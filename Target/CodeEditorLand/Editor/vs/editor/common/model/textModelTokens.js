import{runWhenGlobalIdle as _}from"../../../../vs/base/common/async.js";import{BugIndicatingError as p,onUnexpectedError as T}from"../../../../vs/base/common/errors.js";import{setTimeout0 as f}from"../../../../vs/base/common/platform.js";import{StopWatch as I}from"../../../../vs/base/common/stopwatch.js";import{countEOL as b}from"../../../../vs/editor/common/core/eolCounter.js";import{LineRange as h}from"../../../../vs/editor/common/core/lineRange.js";import{OffsetRange as u}from"../../../../vs/editor/common/core/offsetRange.js";import"../../../../vs/editor/common/core/position.js";import{StandardTokenType as m}from"../../../../vs/editor/common/encodedTokenAttributes.js";import"../../../../vs/editor/common/languages.js";import{nullTokenizeEncoded as L}from"../../../../vs/editor/common/languages/nullTokenize.js";import"../../../../vs/editor/common/model.js";import{FixedArray as v}from"../../../../vs/editor/common/model/fixedArray.js";import"../../../../vs/editor/common/textModelEvents.js";import{ContiguousMultilineTokensBuilder as z}from"../../../../vs/editor/common/tokens/contiguousMultilineTokensBuilder.js";import{LineTokens as S}from"../../../../vs/editor/common/tokens/lineTokens.js";var E=(e=>(e[e.CHEAP_TOKENIZATION_LENGTH_LIMIT=2048]="CHEAP_TOKENIZATION_LENGTH_LIMIT",e))(E||{});class x{constructor(e,t){this.tokenizationSupport=t;this.store=new C(e)}initialState=this.tokenizationSupport.getInitialState();store;getStartState(e){return this.store.getStartState(e,this.initialState)}getFirstInvalidLine(){return this.store.getFirstInvalidLine(this.initialState)}}class re extends x{constructor(t,n,r,i){super(t,n);this._textModel=r;this._languageIdCodec=i}updateTokensUntilLine(t,n){const r=this._textModel.getLanguageId();for(;;){const i=this.getFirstInvalidLine();if(!i||i.lineNumber>n)break;const s=this._textModel.getLineContent(i.lineNumber),a=c(this._languageIdCodec,r,this.tokenizationSupport,s,!0,i.startState);t.add(i.lineNumber,a.tokens),this.store.setEndState(i.lineNumber,a.endState)}}getTokenTypeIfInsertingCharacter(t,n){const r=this.getStartState(t.lineNumber);if(!r)return m.Other;const i=this._textModel.getLanguageId(),s=this._textModel.getLineContent(t.lineNumber),a=s.substring(0,t.column-1)+n+s.substring(t.column-1),o=c(this._languageIdCodec,i,this.tokenizationSupport,a,!0,r),l=new S(o.tokens,a,this._languageIdCodec);if(l.getCount()===0)return m.Other;const g=l.findTokenIndexAtOffset(t.column-1);return l.getStandardTokenType(g)}tokenizeLineWithEdit(t,n,r){const i=t.lineNumber,s=t.column,a=this.getStartState(i);if(!a)return null;const o=this._textModel.getLineContent(i),l=o.substring(0,s-1)+r+o.substring(s-1+n),g=this._textModel.getLanguageIdAtPosition(i,0),k=c(this._languageIdCodec,g,this.tokenizationSupport,l,!0,a);return new S(k.tokens,l,this._languageIdCodec)}hasAccurateTokensForLine(t){const n=this.store.getFirstInvalidEndStateLineNumberOrMax();return t<n}isCheapToTokenize(t){const n=this.store.getFirstInvalidEndStateLineNumberOrMax();return t<n||t===n&&this._textModel.getLineLength(t)<2048}tokenizeHeuristically(t,n,r){if(r<=this.store.getFirstInvalidEndStateLineNumberOrMax())return{heuristicTokens:!1};if(n<=this.store.getFirstInvalidEndStateLineNumberOrMax())return this.updateTokensUntilLine(t,r),{heuristicTokens:!1};let i=this.guessStartState(n);const s=this._textModel.getLanguageId();for(let a=n;a<=r;a++){const o=this._textModel.getLineContent(a),l=c(this._languageIdCodec,s,this.tokenizationSupport,o,!0,i);t.add(a,l.tokens),i=l.endState}return{heuristicTokens:!0}}guessStartState(t){let n=this._textModel.getLineFirstNonWhitespaceColumn(t);const r=[];let i=null;for(let o=t-1;n>1&&o>=1;o--){const l=this._textModel.getLineFirstNonWhitespaceColumn(o);if(l!==0&&l<n&&(r.push(this._textModel.getLineContent(o)),n=l,i=this.getStartState(o),i))break}i||(i=this.tokenizationSupport.getInitialState()),r.reverse();const s=this._textModel.getLanguageId();let a=i;for(const o of r)a=c(this._languageIdCodec,s,this.tokenizationSupport,o,!1,a).endState;return a}}class C{constructor(e){this.lineCount=e;this._invalidEndStatesLineNumbers.addRange(new u(1,e+1))}_tokenizationStateStore=new M;_invalidEndStatesLineNumbers=new N;getEndState(e){return this._tokenizationStateStore.getEndState(e)}setEndState(e,t){if(!t)throw new p("Cannot set null/undefined state");this._invalidEndStatesLineNumbers.delete(e);const n=this._tokenizationStateStore.setEndState(e,t);return n&&e<this.lineCount&&this._invalidEndStatesLineNumbers.addRange(new u(e+1,e+2)),n}acceptChange(e,t){this.lineCount+=t-e.length,this._tokenizationStateStore.acceptChange(e,t),this._invalidEndStatesLineNumbers.addRangeAndResize(new u(e.startLineNumber,e.endLineNumberExclusive),t)}acceptChanges(e){for(const t of e){const[n]=b(t.text);this.acceptChange(new h(t.range.startLineNumber,t.range.endLineNumber+1),n+1)}}invalidateEndStateRange(e){this._invalidEndStatesLineNumbers.addRange(new u(e.startLineNumber,e.endLineNumberExclusive))}getFirstInvalidEndStateLineNumber(){return this._invalidEndStatesLineNumbers.min}getFirstInvalidEndStateLineNumberOrMax(){return this.getFirstInvalidEndStateLineNumber()||Number.MAX_SAFE_INTEGER}allStatesValid(){return this._invalidEndStatesLineNumbers.min===null}getStartState(e,t){return e===1?t:this.getEndState(e-1)}getFirstInvalidLine(e){const t=this.getFirstInvalidEndStateLineNumber();if(t===null)return null;const n=this.getStartState(t,e);if(!n)throw new p("Start state must be defined");return{lineNumber:t,startState:n}}}class M{_lineEndStates=new v(null);getEndState(e){return this._lineEndStates.get(e)}setEndState(e,t){const n=this._lineEndStates.get(e);return n&&n.equals(t)?!1:(this._lineEndStates.set(e,t),!0)}acceptChange(e,t){let n=e.length;t>0&&n>0&&(n--,t--),this._lineEndStates.replace(e.startLineNumber,n,t)}acceptChanges(e){for(const t of e){const[n]=b(t.text);this.acceptChange(new h(t.range.startLineNumber,t.range.endLineNumber+1),n+1)}}}class N{_ranges=[];getRanges(){return this._ranges}get min(){return this._ranges.length===0?null:this._ranges[0].start}removeMin(){if(this._ranges.length===0)return null;const e=this._ranges[0];return e.start+1===e.endExclusive?this._ranges.shift():this._ranges[0]=new u(e.start+1,e.endExclusive),e.start}delete(e){const t=this._ranges.findIndex(n=>n.contains(e));if(t!==-1){const n=this._ranges[t];n.start===e?n.endExclusive===e+1?this._ranges.splice(t,1):this._ranges[t]=new u(e+1,n.endExclusive):n.endExclusive===e+1?this._ranges[t]=new u(n.start,e):this._ranges.splice(t,1,new u(n.start,e),new u(e+1,n.endExclusive))}}addRange(e){u.addRange(e,this._ranges)}addRangeAndResize(e,t){let n=0;for(;!(n>=this._ranges.length||e.start<=this._ranges[n].endExclusive);)n++;let r=n;for(;!(r>=this._ranges.length||e.endExclusive<this._ranges[r].start);)r++;const i=t-e.length;for(let s=r;s<this._ranges.length;s++)this._ranges[s]=this._ranges[s].delta(i);if(n===r){const s=new u(e.start,e.start+t);s.isEmpty||this._ranges.splice(n,0,s)}else{const s=Math.min(e.start,this._ranges[n].start),a=Math.max(e.endExclusive,this._ranges[r-1].endExclusive),o=new u(s,a+i);o.isEmpty?this._ranges.splice(n,r-n):this._ranges.splice(n,r-n,o)}}toString(){return this._ranges.map(e=>e.toString()).join(" + ")}}function c(d,e,t,n,r,i){let s=null;if(t)try{s=t.tokenizeEncoded(n,r,i.clone())}catch(a){T(a)}return s||(s=L(d.encodeLanguageId(e),i)),S.convertToEndOffset(s.tokens,n.length),s}class se{constructor(e,t){this._tokenizerWithStateStore=e;this._backgroundTokenStore=t}_isDisposed=!1;dispose(){this._isDisposed=!0}handleChanges(){this._beginBackgroundTokenization()}_isScheduled=!1;_beginBackgroundTokenization(){this._isScheduled||!this._tokenizerWithStateStore._textModel.isAttachedToEditor()||!this._hasLinesToTokenize()||(this._isScheduled=!0,_(e=>{this._isScheduled=!1,this._backgroundTokenizeWithDeadline(e)}))}_backgroundTokenizeWithDeadline(e){const t=Date.now()+e.timeRemaining(),n=()=>{this._isDisposed||!this._tokenizerWithStateStore._textModel.isAttachedToEditor()||!this._hasLinesToTokenize()||(this._backgroundTokenizeForAtLeast1ms(),Date.now()<t?f(n):this._beginBackgroundTokenization())};n()}_backgroundTokenizeForAtLeast1ms(){const e=this._tokenizerWithStateStore._textModel.getLineCount(),t=new z,n=I.create(!1);do if(n.elapsed()>1||this._tokenizeOneInvalidLine(t)>=e)break;while(this._hasLinesToTokenize());this._backgroundTokenStore.setTokens(t.finalize()),this.checkFinished()}_hasLinesToTokenize(){return this._tokenizerWithStateStore?!this._tokenizerWithStateStore.store.allStatesValid():!1}_tokenizeOneInvalidLine(e){const t=this._tokenizerWithStateStore?.getFirstInvalidLine();return t?(this._tokenizerWithStateStore.updateTokensUntilLine(e,t.lineNumber),t.lineNumber):this._tokenizerWithStateStore._textModel.getLineCount()+1}checkFinished(){this._isDisposed||this._tokenizerWithStateStore.store.allStatesValid()&&this._backgroundTokenStore.backgroundTokenizationFinished()}requestTokens(e,t){this._tokenizerWithStateStore.store.invalidateEndStateRange(new h(e,t))}}export{se as DefaultBackgroundTokenizer,N as RangePriorityQueueImpl,M as TokenizationStateStore,x as TokenizerWithStateStore,re as TokenizerWithStateStoreAndTextModel,C as TrackingTokenizationStateStore};
