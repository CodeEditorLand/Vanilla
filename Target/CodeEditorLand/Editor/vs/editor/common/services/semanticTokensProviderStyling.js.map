{
  "version": 3,
  "sources": ["../../../../../../../Dependency/CodeEditorLand/Editor/Source/vs/editor/common/services/semanticTokensProviderStyling.ts"],
  "sourcesContent": ["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nimport { ILogService, LogLevel } from \"../../../platform/log/common/log.js\";\nimport { IThemeService } from \"../../../platform/theme/common/themeService.js\";\nimport {\n\tFontStyle,\n\tMetadataConsts,\n\tTokenMetadata,\n} from \"../encodedTokenAttributes.js\";\nimport type { SemanticTokens, SemanticTokensLegend } from \"../languages.js\";\nimport { ILanguageService } from \"../languages/language.js\";\nimport { SparseMultilineTokens } from \"../tokens/sparseMultilineTokens.js\";\n\nenum SemanticTokensProviderStylingConstants {\n\tNO_STYLING = 0b01111111111111111111111111111111,\n}\n\nconst ENABLE_TRACE = false;\n\nexport class SemanticTokensProviderStyling {\n\tprivate readonly _hashTable: HashTable;\n\tprivate _hasWarnedOverlappingTokens = false;\n\tprivate _hasWarnedInvalidLengthTokens = false;\n\tprivate _hasWarnedInvalidEditStart = false;\n\n\tconstructor(\n\t\tprivate readonly _legend: SemanticTokensLegend,\n\t\t@IThemeService private readonly _themeService: IThemeService,\n\t\t@ILanguageService private readonly _languageService: ILanguageService,\n\t\t@ILogService private readonly _logService: ILogService\n\t) {\n\t\tthis._hashTable = new HashTable();\n\t}\n\n\tpublic getMetadata(\n\t\ttokenTypeIndex: number,\n\t\ttokenModifierSet: number,\n\t\tlanguageId: string,\n\t): number {\n\t\tconst encodedLanguageId =\n\t\t\tthis._languageService.languageIdCodec.encodeLanguageId(languageId);\n\t\tconst entry = this._hashTable.get(\n\t\t\ttokenTypeIndex,\n\t\t\ttokenModifierSet,\n\t\t\tencodedLanguageId,\n\t\t);\n\t\tlet metadata: number;\n\t\tif (entry) {\n\t\t\tmetadata = entry.metadata;\n\t\t\tif (\n\t\t\t\tENABLE_TRACE &&\n\t\t\t\tthis._logService.getLevel() === LogLevel.Trace\n\t\t\t) {\n\t\t\t\tthis._logService.trace(\n\t\t\t\t\t`SemanticTokensProviderStyling [CACHED] ${tokenTypeIndex} / ${tokenModifierSet}: foreground ${TokenMetadata.getForeground(metadata)}, fontStyle ${TokenMetadata.getFontStyle(metadata).toString(2)}`,\n\t\t\t\t);\n\t\t\t}\n\t\t} else {\n\t\t\tlet tokenType = this._legend.tokenTypes[tokenTypeIndex];\n\t\t\tconst tokenModifiers: string[] = [];\n\t\t\tif (tokenType) {\n\t\t\t\tlet modifierSet = tokenModifierSet;\n\t\t\t\tfor (\n\t\t\t\t\tlet modifierIndex = 0;\n\t\t\t\t\tmodifierSet > 0 &&\n\t\t\t\t\tmodifierIndex < this._legend.tokenModifiers.length;\n\t\t\t\t\tmodifierIndex++\n\t\t\t\t) {\n\t\t\t\t\tif (modifierSet & 1) {\n\t\t\t\t\t\ttokenModifiers.push(\n\t\t\t\t\t\t\tthis._legend.tokenModifiers[modifierIndex],\n\t\t\t\t\t\t);\n\t\t\t\t\t}\n\t\t\t\t\tmodifierSet = modifierSet >> 1;\n\t\t\t\t}\n\t\t\t\tif (\n\t\t\t\t\tENABLE_TRACE &&\n\t\t\t\t\tmodifierSet > 0 &&\n\t\t\t\t\tthis._logService.getLevel() === LogLevel.Trace\n\t\t\t\t) {\n\t\t\t\t\tthis._logService.trace(\n\t\t\t\t\t\t`SemanticTokensProviderStyling: unknown token modifier index: ${tokenModifierSet.toString(2)} for legend: ${JSON.stringify(this._legend.tokenModifiers)}`,\n\t\t\t\t\t);\n\t\t\t\t\ttokenModifiers.push(\"not-in-legend\");\n\t\t\t\t}\n\n\t\t\t\tconst tokenStyle = this._themeService\n\t\t\t\t\t.getColorTheme()\n\t\t\t\t\t.getTokenStyleMetadata(\n\t\t\t\t\t\ttokenType,\n\t\t\t\t\t\ttokenModifiers,\n\t\t\t\t\t\tlanguageId,\n\t\t\t\t\t);\n\t\t\t\tif (typeof tokenStyle === \"undefined\") {\n\t\t\t\t\tmetadata =\n\t\t\t\t\t\tSemanticTokensProviderStylingConstants.NO_STYLING;\n\t\t\t\t} else {\n\t\t\t\t\tmetadata = 0;\n\t\t\t\t\tif (typeof tokenStyle.italic !== \"undefined\") {\n\t\t\t\t\t\tconst italicBit =\n\t\t\t\t\t\t\t(tokenStyle.italic ? FontStyle.Italic : 0) <<\n\t\t\t\t\t\t\tMetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |=\n\t\t\t\t\t\t\titalicBit | MetadataConsts.SEMANTIC_USE_ITALIC;\n\t\t\t\t\t}\n\t\t\t\t\tif (typeof tokenStyle.bold !== \"undefined\") {\n\t\t\t\t\t\tconst boldBit =\n\t\t\t\t\t\t\t(tokenStyle.bold ? FontStyle.Bold : 0) <<\n\t\t\t\t\t\t\tMetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |= boldBit | MetadataConsts.SEMANTIC_USE_BOLD;\n\t\t\t\t\t}\n\t\t\t\t\tif (typeof tokenStyle.underline !== \"undefined\") {\n\t\t\t\t\t\tconst underlineBit =\n\t\t\t\t\t\t\t(tokenStyle.underline ? FontStyle.Underline : 0) <<\n\t\t\t\t\t\t\tMetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |=\n\t\t\t\t\t\t\tunderlineBit |\n\t\t\t\t\t\t\tMetadataConsts.SEMANTIC_USE_UNDERLINE;\n\t\t\t\t\t}\n\t\t\t\t\tif (typeof tokenStyle.strikethrough !== \"undefined\") {\n\t\t\t\t\t\tconst strikethroughBit =\n\t\t\t\t\t\t\t(tokenStyle.strikethrough\n\t\t\t\t\t\t\t\t? FontStyle.Strikethrough\n\t\t\t\t\t\t\t\t: 0) << MetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |=\n\t\t\t\t\t\t\tstrikethroughBit |\n\t\t\t\t\t\t\tMetadataConsts.SEMANTIC_USE_STRIKETHROUGH;\n\t\t\t\t\t}\n\t\t\t\t\tif (tokenStyle.foreground) {\n\t\t\t\t\t\tconst foregroundBits =\n\t\t\t\t\t\t\ttokenStyle.foreground <<\n\t\t\t\t\t\t\tMetadataConsts.FOREGROUND_OFFSET;\n\t\t\t\t\t\tmetadata |=\n\t\t\t\t\t\t\tforegroundBits |\n\t\t\t\t\t\t\tMetadataConsts.SEMANTIC_USE_FOREGROUND;\n\t\t\t\t\t}\n\t\t\t\t\tif (metadata === 0) {\n\t\t\t\t\t\t// Nothing!\n\t\t\t\t\t\tmetadata =\n\t\t\t\t\t\t\tSemanticTokensProviderStylingConstants.NO_STYLING;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (\n\t\t\t\t\tENABLE_TRACE &&\n\t\t\t\t\tthis._logService.getLevel() === LogLevel.Trace\n\t\t\t\t) {\n\t\t\t\t\tthis._logService.trace(\n\t\t\t\t\t\t`SemanticTokensProviderStyling: unknown token type index: ${tokenTypeIndex} for legend: ${JSON.stringify(this._legend.tokenTypes)}`,\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t\tmetadata = SemanticTokensProviderStylingConstants.NO_STYLING;\n\t\t\t\ttokenType = \"not-in-legend\";\n\t\t\t}\n\t\t\tthis._hashTable.add(\n\t\t\t\ttokenTypeIndex,\n\t\t\t\ttokenModifierSet,\n\t\t\t\tencodedLanguageId,\n\t\t\t\tmetadata,\n\t\t\t);\n\n\t\t\tif (\n\t\t\t\tENABLE_TRACE &&\n\t\t\t\tthis._logService.getLevel() === LogLevel.Trace\n\t\t\t) {\n\t\t\t\tthis._logService.trace(\n\t\t\t\t\t`SemanticTokensProviderStyling ${tokenTypeIndex} (${tokenType}) / ${tokenModifierSet} (${tokenModifiers.join(\" \")}): foreground ${TokenMetadata.getForeground(metadata)}, fontStyle ${TokenMetadata.getFontStyle(metadata).toString(2)}`,\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\n\t\treturn metadata;\n\t}\n\n\tpublic warnOverlappingSemanticTokens(\n\t\tlineNumber: number,\n\t\tstartColumn: number,\n\t): void {\n\t\tif (!this._hasWarnedOverlappingTokens) {\n\t\t\tthis._hasWarnedOverlappingTokens = true;\n\t\t\tthis._logService.warn(\n\t\t\t\t`Overlapping semantic tokens detected at lineNumber ${lineNumber}, column ${startColumn}`,\n\t\t\t);\n\t\t}\n\t}\n\n\tpublic warnInvalidLengthSemanticTokens(\n\t\tlineNumber: number,\n\t\tstartColumn: number,\n\t): void {\n\t\tif (!this._hasWarnedInvalidLengthTokens) {\n\t\t\tthis._hasWarnedInvalidLengthTokens = true;\n\t\t\tthis._logService.warn(\n\t\t\t\t`Semantic token with invalid length detected at lineNumber ${lineNumber}, column ${startColumn}`,\n\t\t\t);\n\t\t}\n\t}\n\n\tpublic warnInvalidEditStart(\n\t\tpreviousResultId: string | undefined,\n\t\tresultId: string | undefined,\n\t\teditIndex: number,\n\t\teditStart: number,\n\t\tmaxExpectedStart: number,\n\t): void {\n\t\tif (!this._hasWarnedInvalidEditStart) {\n\t\t\tthis._hasWarnedInvalidEditStart = true;\n\t\t\tthis._logService.warn(\n\t\t\t\t`Invalid semantic tokens edit detected (previousResultId: ${previousResultId}, resultId: ${resultId}) at edit #${editIndex}: The provided start offset ${editStart} is outside the previous data (length ${maxExpectedStart}).`,\n\t\t\t);\n\t\t}\n\t}\n}\n\nenum SemanticColoringConstants {\n\t/**\n\t * Let's aim at having 8KB buffers if possible...\n\t * So that would be 8192 / (5 * 4) = 409.6 tokens per area\n\t */\n\tDesiredTokensPerArea = 400,\n\n\t/**\n\t * Try to keep the total number of areas under 1024 if possible,\n\t * simply compensate by having more tokens per area...\n\t */\n\tDesiredMaxAreas = 1024,\n}\n\nexport function toMultilineTokens2(\n\ttokens: SemanticTokens,\n\tstyling: SemanticTokensProviderStyling,\n\tlanguageId: string,\n): SparseMultilineTokens[] {\n\tconst srcData = tokens.data;\n\tconst tokenCount = (tokens.data.length / 5) | 0;\n\tconst tokensPerArea = Math.max(\n\t\tMath.ceil(tokenCount / SemanticColoringConstants.DesiredMaxAreas),\n\t\tSemanticColoringConstants.DesiredTokensPerArea,\n\t);\n\tconst result: SparseMultilineTokens[] = [];\n\n\tlet tokenIndex = 0;\n\tlet lastLineNumber = 1;\n\tlet lastStartCharacter = 0;\n\twhile (tokenIndex < tokenCount) {\n\t\tconst tokenStartIndex = tokenIndex;\n\t\tlet tokenEndIndex = Math.min(\n\t\t\ttokenStartIndex + tokensPerArea,\n\t\t\ttokenCount,\n\t\t);\n\n\t\t// Keep tokens on the same line in the same area...\n\t\tif (tokenEndIndex < tokenCount) {\n\t\t\tlet smallTokenEndIndex = tokenEndIndex;\n\t\t\twhile (\n\t\t\t\tsmallTokenEndIndex - 1 > tokenStartIndex &&\n\t\t\t\tsrcData[5 * smallTokenEndIndex] === 0\n\t\t\t) {\n\t\t\t\tsmallTokenEndIndex--;\n\t\t\t}\n\n\t\t\tif (smallTokenEndIndex - 1 === tokenStartIndex) {\n\t\t\t\t// there are so many tokens on this line that our area would be empty, we must now go right\n\t\t\t\tlet bigTokenEndIndex = tokenEndIndex;\n\t\t\t\twhile (\n\t\t\t\t\tbigTokenEndIndex + 1 < tokenCount &&\n\t\t\t\t\tsrcData[5 * bigTokenEndIndex] === 0\n\t\t\t\t) {\n\t\t\t\t\tbigTokenEndIndex++;\n\t\t\t\t}\n\t\t\t\ttokenEndIndex = bigTokenEndIndex;\n\t\t\t} else {\n\t\t\t\ttokenEndIndex = smallTokenEndIndex;\n\t\t\t}\n\t\t}\n\n\t\tlet destData = new Uint32Array((tokenEndIndex - tokenStartIndex) * 4);\n\t\tlet destOffset = 0;\n\t\tlet areaLine = 0;\n\t\tlet prevLineNumber = 0;\n\t\tlet prevEndCharacter = 0;\n\t\twhile (tokenIndex < tokenEndIndex) {\n\t\t\tconst srcOffset = 5 * tokenIndex;\n\t\t\tconst deltaLine = srcData[srcOffset];\n\t\t\tconst deltaCharacter = srcData[srcOffset + 1];\n\t\t\t// Casting both `lineNumber`, `startCharacter` and `endCharacter` here to uint32 using `|0`\n\t\t\t// to validate below with the actual values that will be inserted in the Uint32Array result\n\t\t\tconst lineNumber = (lastLineNumber + deltaLine) | 0;\n\t\t\tconst startCharacter =\n\t\t\t\tdeltaLine === 0\n\t\t\t\t\t? (lastStartCharacter + deltaCharacter) | 0\n\t\t\t\t\t: deltaCharacter;\n\t\t\tconst length = srcData[srcOffset + 2];\n\t\t\tconst endCharacter = (startCharacter + length) | 0;\n\t\t\tconst tokenTypeIndex = srcData[srcOffset + 3];\n\t\t\tconst tokenModifierSet = srcData[srcOffset + 4];\n\n\t\t\tif (endCharacter <= startCharacter) {\n\t\t\t\t// this token is invalid (most likely a negative length casted to uint32)\n\t\t\t\tstyling.warnInvalidLengthSemanticTokens(\n\t\t\t\t\tlineNumber,\n\t\t\t\t\tstartCharacter + 1,\n\t\t\t\t);\n\t\t\t} else if (\n\t\t\t\tprevLineNumber === lineNumber &&\n\t\t\t\tprevEndCharacter > startCharacter\n\t\t\t) {\n\t\t\t\t// this token overlaps with the previous token\n\t\t\t\tstyling.warnOverlappingSemanticTokens(\n\t\t\t\t\tlineNumber,\n\t\t\t\t\tstartCharacter + 1,\n\t\t\t\t);\n\t\t\t} else {\n\t\t\t\tconst metadata = styling.getMetadata(\n\t\t\t\t\ttokenTypeIndex,\n\t\t\t\t\ttokenModifierSet,\n\t\t\t\t\tlanguageId,\n\t\t\t\t);\n\n\t\t\t\tif (\n\t\t\t\t\tmetadata !==\n\t\t\t\t\tSemanticTokensProviderStylingConstants.NO_STYLING\n\t\t\t\t) {\n\t\t\t\t\tif (areaLine === 0) {\n\t\t\t\t\t\tareaLine = lineNumber;\n\t\t\t\t\t}\n\t\t\t\t\tdestData[destOffset] = lineNumber - areaLine;\n\t\t\t\t\tdestData[destOffset + 1] = startCharacter;\n\t\t\t\t\tdestData[destOffset + 2] = endCharacter;\n\t\t\t\t\tdestData[destOffset + 3] = metadata;\n\t\t\t\t\tdestOffset += 4;\n\n\t\t\t\t\tprevLineNumber = lineNumber;\n\t\t\t\t\tprevEndCharacter = endCharacter;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tlastLineNumber = lineNumber;\n\t\t\tlastStartCharacter = startCharacter;\n\t\t\ttokenIndex++;\n\t\t}\n\n\t\tif (destOffset !== destData.length) {\n\t\t\tdestData = destData.subarray(0, destOffset);\n\t\t}\n\n\t\tconst tokens = SparseMultilineTokens.create(areaLine, destData);\n\t\tresult.push(tokens);\n\t}\n\n\treturn result;\n}\n\nclass HashTableEntry {\n\tpublic readonly tokenTypeIndex: number;\n\tpublic readonly tokenModifierSet: number;\n\tpublic readonly languageId: number;\n\tpublic readonly metadata: number;\n\tpublic next: HashTableEntry | null;\n\n\tconstructor(\n\t\ttokenTypeIndex: number,\n\t\ttokenModifierSet: number,\n\t\tlanguageId: number,\n\t\tmetadata: number,\n\t) {\n\t\tthis.tokenTypeIndex = tokenTypeIndex;\n\t\tthis.tokenModifierSet = tokenModifierSet;\n\t\tthis.languageId = languageId;\n\t\tthis.metadata = metadata;\n\t\tthis.next = null;\n\t}\n}\n\nclass HashTable {\n\tprivate static _SIZES = [\n\t\t3, 7, 13, 31, 61, 127, 251, 509, 1021, 2039, 4093, 8191, 16381, 32749,\n\t\t65521, 131071, 262139, 524287, 1048573, 2097143,\n\t];\n\n\tprivate _elementsCount: number;\n\tprivate _currentLengthIndex: number;\n\tprivate _currentLength: number;\n\tprivate _growCount: number;\n\tprivate _elements: (HashTableEntry | null)[];\n\n\tconstructor() {\n\t\tthis._elementsCount = 0;\n\t\tthis._currentLengthIndex = 0;\n\t\tthis._currentLength = HashTable._SIZES[this._currentLengthIndex];\n\t\tthis._growCount = Math.round(\n\t\t\tthis._currentLengthIndex + 1 < HashTable._SIZES.length\n\t\t\t\t? (2 / 3) * this._currentLength\n\t\t\t\t: 0,\n\t\t);\n\t\tthis._elements = [];\n\t\tHashTable._nullOutEntries(this._elements, this._currentLength);\n\t}\n\n\tprivate static _nullOutEntries(\n\t\tentries: (HashTableEntry | null)[],\n\t\tlength: number,\n\t): void {\n\t\tfor (let i = 0; i < length; i++) {\n\t\t\tentries[i] = null;\n\t\t}\n\t}\n\n\tprivate _hash2(n1: number, n2: number): number {\n\t\treturn ((n1 << 5) - n1 + n2) | 0; // n1 * 31 + n2, keep as int32\n\t}\n\n\tprivate _hashFunc(\n\t\ttokenTypeIndex: number,\n\t\ttokenModifierSet: number,\n\t\tlanguageId: number,\n\t): number {\n\t\treturn (\n\t\t\tthis._hash2(\n\t\t\t\tthis._hash2(tokenTypeIndex, tokenModifierSet),\n\t\t\t\tlanguageId,\n\t\t\t) % this._currentLength\n\t\t);\n\t}\n\n\tpublic get(\n\t\ttokenTypeIndex: number,\n\t\ttokenModifierSet: number,\n\t\tlanguageId: number,\n\t): HashTableEntry | null {\n\t\tconst hash = this._hashFunc(\n\t\t\ttokenTypeIndex,\n\t\t\ttokenModifierSet,\n\t\t\tlanguageId,\n\t\t);\n\n\t\tlet p = this._elements[hash];\n\t\twhile (p) {\n\t\t\tif (\n\t\t\t\tp.tokenTypeIndex === tokenTypeIndex &&\n\t\t\t\tp.tokenModifierSet === tokenModifierSet &&\n\t\t\t\tp.languageId === languageId\n\t\t\t) {\n\t\t\t\treturn p;\n\t\t\t}\n\t\t\tp = p.next;\n\t\t}\n\n\t\treturn null;\n\t}\n\n\tpublic add(\n\t\ttokenTypeIndex: number,\n\t\ttokenModifierSet: number,\n\t\tlanguageId: number,\n\t\tmetadata: number,\n\t): void {\n\t\tthis._elementsCount++;\n\t\tif (this._growCount !== 0 && this._elementsCount >= this._growCount) {\n\t\t\t// expand!\n\t\t\tconst oldElements = this._elements;\n\n\t\t\tthis._currentLengthIndex++;\n\t\t\tthis._currentLength = HashTable._SIZES[this._currentLengthIndex];\n\t\t\tthis._growCount = Math.round(\n\t\t\t\tthis._currentLengthIndex + 1 < HashTable._SIZES.length\n\t\t\t\t\t? (2 / 3) * this._currentLength\n\t\t\t\t\t: 0,\n\t\t\t);\n\t\t\tthis._elements = [];\n\t\t\tHashTable._nullOutEntries(this._elements, this._currentLength);\n\n\t\t\tfor (const first of oldElements) {\n\t\t\t\tlet p = first;\n\t\t\t\twhile (p) {\n\t\t\t\t\tconst oldNext = p.next;\n\t\t\t\t\tp.next = null;\n\t\t\t\t\tthis._add(p);\n\t\t\t\t\tp = oldNext;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tthis._add(\n\t\t\tnew HashTableEntry(\n\t\t\t\ttokenTypeIndex,\n\t\t\t\ttokenModifierSet,\n\t\t\t\tlanguageId,\n\t\t\t\tmetadata,\n\t\t\t),\n\t\t);\n\t}\n\n\tprivate _add(element: HashTableEntry): void {\n\t\tconst hash = this._hashFunc(\n\t\t\telement.tokenTypeIndex,\n\t\t\telement.tokenModifierSet,\n\t\t\telement.languageId,\n\t\t);\n\t\telement.next = this._elements[hash];\n\t\tthis._elements[hash] = element;\n\t}\n}\n"],
  "mappings": ";;;;;;;;;;;;AAKA,SAAS,aAAa,gBAAgB;AACtC,SAAS,qBAAqB;AAC9B;AAAA,EACC;AAAA,EACA;AAAA,EACA;AAAA,OACM;AAEP,SAAS,wBAAwB;AACjC,SAAS,6BAA6B;AAEtC,IAAK,yCAAL,kBAAKA,4CAAL;AACC,EAAAA,gFAAA,gBAAa,cAAb;AADI,SAAAA;AAAA,GAAA;AAIL,MAAM,eAAe;AAEd,IAAM,gCAAN,MAAoC;AAAA,EAM1C,YACkB,SACe,eACG,kBACL,aAC7B;AAJgB;AACe;AACG;AACL;AAE9B,SAAK,aAAa,IAAI,UAAU;AAAA,EACjC;AAAA,EAnCD,OAsB2C;AAAA;AAAA;AAAA,EACzB;AAAA,EACT,8BAA8B;AAAA,EAC9B,gCAAgC;AAAA,EAChC,6BAA6B;AAAA,EAW9B,YACN,gBACA,kBACA,YACS;AACT,UAAM,oBACL,KAAK,iBAAiB,gBAAgB,iBAAiB,UAAU;AAClE,UAAM,QAAQ,KAAK,WAAW;AAAA,MAC7B;AAAA,MACA;AAAA,MACA;AAAA,IACD;AACA,QAAI;AACJ,QAAI,OAAO;AACV,iBAAW,MAAM;AACjB,UACC,gBACA,KAAK,YAAY,SAAS,MAAM,SAAS,OACxC;AACD,aAAK,YAAY;AAAA,UAChB,0CAA0C,cAAc,MAAM,gBAAgB,gBAAgB,cAAc,cAAc,QAAQ,CAAC,eAAe,cAAc,aAAa,QAAQ,EAAE,SAAS,CAAC,CAAC;AAAA,QACnM;AAAA,MACD;AAAA,IACD,OAAO;AACN,UAAI,YAAY,KAAK,QAAQ,WAAW,cAAc;AACtD,YAAM,iBAA2B,CAAC;AAClC,UAAI,WAAW;AACd,YAAI,cAAc;AAClB,iBACK,gBAAgB,GACpB,cAAc,KACd,gBAAgB,KAAK,QAAQ,eAAe,QAC5C,iBACC;AACD,cAAI,cAAc,GAAG;AACpB,2BAAe;AAAA,cACd,KAAK,QAAQ,eAAe,aAAa;AAAA,YAC1C;AAAA,UACD;AACA,wBAAc,eAAe;AAAA,QAC9B;AACA,YACC,gBACA,cAAc,KACd,KAAK,YAAY,SAAS,MAAM,SAAS,OACxC;AACD,eAAK,YAAY;AAAA,YAChB,gEAAgE,iBAAiB,SAAS,CAAC,CAAC,gBAAgB,KAAK,UAAU,KAAK,QAAQ,cAAc,CAAC;AAAA,UACxJ;AACA,yBAAe,KAAK,eAAe;AAAA,QACpC;AAEA,cAAM,aAAa,KAAK,cACtB,cAAc,EACd;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACD;AACD,YAAI,OAAO,eAAe,aAAa;AACtC,qBACC;AAAA,QACF,OAAO;AACN,qBAAW;AACX,cAAI,OAAO,WAAW,WAAW,aAAa;AAC7C,kBAAM,aACJ,WAAW,SAAS,UAAU,SAAS,MACxC,eAAe;AAChB,wBACC,YAAY,eAAe;AAAA,UAC7B;AACA,cAAI,OAAO,WAAW,SAAS,aAAa;AAC3C,kBAAM,WACJ,WAAW,OAAO,UAAU,OAAO,MACpC,eAAe;AAChB,wBAAY,UAAU,eAAe;AAAA,UACtC;AACA,cAAI,OAAO,WAAW,cAAc,aAAa;AAChD,kBAAM,gBACJ,WAAW,YAAY,UAAU,YAAY,MAC9C,eAAe;AAChB,wBACC,eACA,eAAe;AAAA,UACjB;AACA,cAAI,OAAO,WAAW,kBAAkB,aAAa;AACpD,kBAAM,oBACJ,WAAW,gBACT,UAAU,gBACV,MAAM,eAAe;AACzB,wBACC,mBACA,eAAe;AAAA,UACjB;AACA,cAAI,WAAW,YAAY;AAC1B,kBAAM,iBACL,WAAW,cACX,eAAe;AAChB,wBACC,iBACA,eAAe;AAAA,UACjB;AACA,cAAI,aAAa,GAAG;AAEnB,uBACC;AAAA,UACF;AAAA,QACD;AAAA,MACD,OAAO;AACN,YACC,gBACA,KAAK,YAAY,SAAS,MAAM,SAAS,OACxC;AACD,eAAK,YAAY;AAAA,YAChB,4DAA4D,cAAc,gBAAgB,KAAK,UAAU,KAAK,QAAQ,UAAU,CAAC;AAAA,UAClI;AAAA,QACD;AACA,mBAAW;AACX,oBAAY;AAAA,MACb;AACA,WAAK,WAAW;AAAA,QACf;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MACD;AAEA,UACC,gBACA,KAAK,YAAY,SAAS,MAAM,SAAS,OACxC;AACD,aAAK,YAAY;AAAA,UAChB,iCAAiC,cAAc,KAAK,SAAS,OAAO,gBAAgB,KAAK,eAAe,KAAK,GAAG,CAAC,iBAAiB,cAAc,cAAc,QAAQ,CAAC,eAAe,cAAc,aAAa,QAAQ,EAAE,SAAS,CAAC,CAAC;AAAA,QACvO;AAAA,MACD;AAAA,IACD;AAEA,WAAO;AAAA,EACR;AAAA,EAEO,8BACN,YACA,aACO;AACP,QAAI,CAAC,KAAK,6BAA6B;AACtC,WAAK,8BAA8B;AACnC,WAAK,YAAY;AAAA,QAChB,sDAAsD,UAAU,YAAY,WAAW;AAAA,MACxF;AAAA,IACD;AAAA,EACD;AAAA,EAEO,gCACN,YACA,aACO;AACP,QAAI,CAAC,KAAK,+BAA+B;AACxC,WAAK,gCAAgC;AACrC,WAAK,YAAY;AAAA,QAChB,6DAA6D,UAAU,YAAY,WAAW;AAAA,MAC/F;AAAA,IACD;AAAA,EACD;AAAA,EAEO,qBACN,kBACA,UACA,WACA,WACA,kBACO;AACP,QAAI,CAAC,KAAK,4BAA4B;AACrC,WAAK,6BAA6B;AAClC,WAAK,YAAY;AAAA,QAChB,4DAA4D,gBAAgB,eAAe,QAAQ,cAAc,SAAS,+BAA+B,SAAS,yCAAyC,gBAAgB;AAAA,MAC5N;AAAA,IACD;AAAA,EACD;AACD;AAjMa,gCAAN;AAAA,EAQJ;AAAA,EACA;AAAA,EACA;AAAA,GAVU;AAmMb,IAAK,4BAAL,kBAAKC,+BAAL;AAKC,EAAAA,sDAAA,0BAAuB,OAAvB;AAMA,EAAAA,sDAAA,qBAAkB,QAAlB;AAXI,SAAAA;AAAA,GAAA;AAcE,SAAS,mBACf,QACA,SACA,YAC0B;AAC1B,QAAM,UAAU,OAAO;AACvB,QAAM,aAAc,OAAO,KAAK,SAAS,IAAK;AAC9C,QAAM,gBAAgB,KAAK;AAAA,IAC1B,KAAK,KAAK,aAAa,0BAAyC;AAAA,IAChE;AAAA,EACD;AACA,QAAM,SAAkC,CAAC;AAEzC,MAAI,aAAa;AACjB,MAAI,iBAAiB;AACrB,MAAI,qBAAqB;AACzB,SAAO,aAAa,YAAY;AAC/B,UAAM,kBAAkB;AACxB,QAAI,gBAAgB,KAAK;AAAA,MACxB,kBAAkB;AAAA,MAClB;AAAA,IACD;AAGA,QAAI,gBAAgB,YAAY;AAC/B,UAAI,qBAAqB;AACzB,aACC,qBAAqB,IAAI,mBACzB,QAAQ,IAAI,kBAAkB,MAAM,GACnC;AACD;AAAA,MACD;AAEA,UAAI,qBAAqB,MAAM,iBAAiB;AAE/C,YAAI,mBAAmB;AACvB,eACC,mBAAmB,IAAI,cACvB,QAAQ,IAAI,gBAAgB,MAAM,GACjC;AACD;AAAA,QACD;AACA,wBAAgB;AAAA,MACjB,OAAO;AACN,wBAAgB;AAAA,MACjB;AAAA,IACD;AAEA,QAAI,WAAW,IAAI,aAAa,gBAAgB,mBAAmB,CAAC;AACpE,QAAI,aAAa;AACjB,QAAI,WAAW;AACf,QAAI,iBAAiB;AACrB,QAAI,mBAAmB;AACvB,WAAO,aAAa,eAAe;AAClC,YAAM,YAAY,IAAI;AACtB,YAAM,YAAY,QAAQ,SAAS;AACnC,YAAM,iBAAiB,QAAQ,YAAY,CAAC;AAG5C,YAAM,aAAc,iBAAiB,YAAa;AAClD,YAAM,iBACL,cAAc,IACV,qBAAqB,iBAAkB,IACxC;AACJ,YAAM,SAAS,QAAQ,YAAY,CAAC;AACpC,YAAM,eAAgB,iBAAiB,SAAU;AACjD,YAAM,iBAAiB,QAAQ,YAAY,CAAC;AAC5C,YAAM,mBAAmB,QAAQ,YAAY,CAAC;AAE9C,UAAI,gBAAgB,gBAAgB;AAEnC,gBAAQ;AAAA,UACP;AAAA,UACA,iBAAiB;AAAA,QAClB;AAAA,MACD,WACC,mBAAmB,cACnB,mBAAmB,gBAClB;AAED,gBAAQ;AAAA,UACP;AAAA,UACA,iBAAiB;AAAA,QAClB;AAAA,MACD,OAAO;AACN,cAAM,WAAW,QAAQ;AAAA,UACxB;AAAA,UACA;AAAA,UACA;AAAA,QACD;AAEA,YACC,aACA,6BACC;AACD,cAAI,aAAa,GAAG;AACnB,uBAAW;AAAA,UACZ;AACA,mBAAS,UAAU,IAAI,aAAa;AACpC,mBAAS,aAAa,CAAC,IAAI;AAC3B,mBAAS,aAAa,CAAC,IAAI;AAC3B,mBAAS,aAAa,CAAC,IAAI;AAC3B,wBAAc;AAEd,2BAAiB;AACjB,6BAAmB;AAAA,QACpB;AAAA,MACD;AAEA,uBAAiB;AACjB,2BAAqB;AACrB;AAAA,IACD;AAEA,QAAI,eAAe,SAAS,QAAQ;AACnC,iBAAW,SAAS,SAAS,GAAG,UAAU;AAAA,IAC3C;AAEA,UAAMC,UAAS,sBAAsB,OAAO,UAAU,QAAQ;AAC9D,WAAO,KAAKA,OAAM;AAAA,EACnB;AAEA,SAAO;AACR;AA3HgB;AA6HhB,MAAM,eAAe;AAAA,EApWrB,OAoWqB;AAAA;AAAA;AAAA,EACJ;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACT;AAAA,EAEP,YACC,gBACA,kBACA,YACA,UACC;AACD,SAAK,iBAAiB;AACtB,SAAK,mBAAmB;AACxB,SAAK,aAAa;AAClB,SAAK,WAAW;AAChB,SAAK,OAAO;AAAA,EACb;AACD;AAEA,MAAM,UAAU;AAAA,EAzXhB,OAyXgB;AAAA;AAAA;AAAA,EACf,OAAe,SAAS;AAAA,IACvB;AAAA,IAAG;AAAA,IAAG;AAAA,IAAI;AAAA,IAAI;AAAA,IAAI;AAAA,IAAK;AAAA,IAAK;AAAA,IAAK;AAAA,IAAM;AAAA,IAAM;AAAA,IAAM;AAAA,IAAM;AAAA,IAAO;AAAA,IAChE;AAAA,IAAO;AAAA,IAAQ;AAAA,IAAQ;AAAA,IAAQ;AAAA,IAAS;AAAA,EACzC;AAAA,EAEQ;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EAER,cAAc;AACb,SAAK,iBAAiB;AACtB,SAAK,sBAAsB;AAC3B,SAAK,iBAAiB,UAAU,OAAO,KAAK,mBAAmB;AAC/D,SAAK,aAAa,KAAK;AAAA,MACtB,KAAK,sBAAsB,IAAI,UAAU,OAAO,SAC5C,IAAI,IAAK,KAAK,iBACf;AAAA,IACJ;AACA,SAAK,YAAY,CAAC;AAClB,cAAU,gBAAgB,KAAK,WAAW,KAAK,cAAc;AAAA,EAC9D;AAAA,EAEA,OAAe,gBACd,SACA,QACO;AACP,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAChC,cAAQ,CAAC,IAAI;AAAA,IACd;AAAA,EACD;AAAA,EAEQ,OAAO,IAAY,IAAoB;AAC9C,YAAS,MAAM,KAAK,KAAK,KAAM;AAAA,EAChC;AAAA,EAEQ,UACP,gBACA,kBACA,YACS;AACT,WACC,KAAK;AAAA,MACJ,KAAK,OAAO,gBAAgB,gBAAgB;AAAA,MAC5C;AAAA,IACD,IAAI,KAAK;AAAA,EAEX;AAAA,EAEO,IACN,gBACA,kBACA,YACwB;AACxB,UAAM,OAAO,KAAK;AAAA,MACjB;AAAA,MACA;AAAA,MACA;AAAA,IACD;AAEA,QAAI,IAAI,KAAK,UAAU,IAAI;AAC3B,WAAO,GAAG;AACT,UACC,EAAE,mBAAmB,kBACrB,EAAE,qBAAqB,oBACvB,EAAE,eAAe,YAChB;AACD,eAAO;AAAA,MACR;AACA,UAAI,EAAE;AAAA,IACP;AAEA,WAAO;AAAA,EACR;AAAA,EAEO,IACN,gBACA,kBACA,YACA,UACO;AACP,SAAK;AACL,QAAI,KAAK,eAAe,KAAK,KAAK,kBAAkB,KAAK,YAAY;AAEpE,YAAM,cAAc,KAAK;AAEzB,WAAK;AACL,WAAK,iBAAiB,UAAU,OAAO,KAAK,mBAAmB;AAC/D,WAAK,aAAa,KAAK;AAAA,QACtB,KAAK,sBAAsB,IAAI,UAAU,OAAO,SAC5C,IAAI,IAAK,KAAK,iBACf;AAAA,MACJ;AACA,WAAK,YAAY,CAAC;AAClB,gBAAU,gBAAgB,KAAK,WAAW,KAAK,cAAc;AAE7D,iBAAW,SAAS,aAAa;AAChC,YAAI,IAAI;AACR,eAAO,GAAG;AACT,gBAAM,UAAU,EAAE;AAClB,YAAE,OAAO;AACT,eAAK,KAAK,CAAC;AACX,cAAI;AAAA,QACL;AAAA,MACD;AAAA,IACD;AACA,SAAK;AAAA,MACJ,IAAI;AAAA,QACH;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MACD;AAAA,IACD;AAAA,EACD;AAAA,EAEQ,KAAK,SAA+B;AAC3C,UAAM,OAAO,KAAK;AAAA,MACjB,QAAQ;AAAA,MACR,QAAQ;AAAA,MACR,QAAQ;AAAA,IACT;AACA,YAAQ,OAAO,KAAK,UAAU,IAAI;AAClC,SAAK,UAAU,IAAI,IAAI;AAAA,EACxB;AACD;",
  "names": ["SemanticTokensProviderStylingConstants", "SemanticColoringConstants", "tokens"]
}
