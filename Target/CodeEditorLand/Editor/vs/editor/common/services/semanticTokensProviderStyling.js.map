{
  "version": 3,
  "sources": ["../../../../../../../Dependency/CodeEditorLand/Editor/Source/vs/editor/common/services/semanticTokensProviderStyling.ts"],
  "sourcesContent": ["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nimport { SemanticTokensLegend, SemanticTokens } from '../languages.js';\nimport { FontStyle, MetadataConsts, TokenMetadata } from '../encodedTokenAttributes.js';\nimport { IThemeService } from '../../../platform/theme/common/themeService.js';\nimport { ILogService, LogLevel } from '../../../platform/log/common/log.js';\nimport { SparseMultilineTokens } from '../tokens/sparseMultilineTokens.js';\nimport { ILanguageService } from '../languages/language.js';\n\nconst enum SemanticTokensProviderStylingConstants {\n\tNO_STYLING = 0b01111111111111111111111111111111\n}\n\nconst ENABLE_TRACE = false;\n\nexport class SemanticTokensProviderStyling {\n\n\tprivate readonly _hashTable: HashTable;\n\tprivate _hasWarnedOverlappingTokens = false;\n\tprivate _hasWarnedInvalidLengthTokens = false;\n\tprivate _hasWarnedInvalidEditStart = false;\n\n\tconstructor(\n\t\tprivate readonly _legend: SemanticTokensLegend,\n\t\t@IThemeService private readonly _themeService: IThemeService,\n\t\t@ILanguageService private readonly _languageService: ILanguageService,\n\t\t@ILogService private readonly _logService: ILogService\n\t) {\n\t\tthis._hashTable = new HashTable();\n\t}\n\n\tpublic getMetadata(tokenTypeIndex: number, tokenModifierSet: number, languageId: string): number {\n\t\tconst encodedLanguageId = this._languageService.languageIdCodec.encodeLanguageId(languageId);\n\t\tconst entry = this._hashTable.get(tokenTypeIndex, tokenModifierSet, encodedLanguageId);\n\t\tlet metadata: number;\n\t\tif (entry) {\n\t\t\tmetadata = entry.metadata;\n\t\t\tif (ENABLE_TRACE && this._logService.getLevel() === LogLevel.Trace) {\n\t\t\t\tthis._logService.trace(`SemanticTokensProviderStyling [CACHED] ${tokenTypeIndex} / ${tokenModifierSet}: foreground ${TokenMetadata.getForeground(metadata)}, fontStyle ${TokenMetadata.getFontStyle(metadata).toString(2)}`);\n\t\t\t}\n\t\t} else {\n\t\t\tlet tokenType = this._legend.tokenTypes[tokenTypeIndex];\n\t\t\tconst tokenModifiers: string[] = [];\n\t\t\tif (tokenType) {\n\t\t\t\tlet modifierSet = tokenModifierSet;\n\t\t\t\tfor (let modifierIndex = 0; modifierSet > 0 && modifierIndex < this._legend.tokenModifiers.length; modifierIndex++) {\n\t\t\t\t\tif (modifierSet & 1) {\n\t\t\t\t\t\ttokenModifiers.push(this._legend.tokenModifiers[modifierIndex]);\n\t\t\t\t\t}\n\t\t\t\t\tmodifierSet = modifierSet >> 1;\n\t\t\t\t}\n\t\t\t\tif (ENABLE_TRACE && modifierSet > 0 && this._logService.getLevel() === LogLevel.Trace) {\n\t\t\t\t\tthis._logService.trace(`SemanticTokensProviderStyling: unknown token modifier index: ${tokenModifierSet.toString(2)} for legend: ${JSON.stringify(this._legend.tokenModifiers)}`);\n\t\t\t\t\ttokenModifiers.push('not-in-legend');\n\t\t\t\t}\n\n\t\t\t\tconst tokenStyle = this._themeService.getColorTheme().getTokenStyleMetadata(tokenType, tokenModifiers, languageId);\n\t\t\t\tif (typeof tokenStyle === 'undefined') {\n\t\t\t\t\tmetadata = SemanticTokensProviderStylingConstants.NO_STYLING;\n\t\t\t\t} else {\n\t\t\t\t\tmetadata = 0;\n\t\t\t\t\tif (typeof tokenStyle.italic !== 'undefined') {\n\t\t\t\t\t\tconst italicBit = (tokenStyle.italic ? FontStyle.Italic : 0) << MetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |= italicBit | MetadataConsts.SEMANTIC_USE_ITALIC;\n\t\t\t\t\t}\n\t\t\t\t\tif (typeof tokenStyle.bold !== 'undefined') {\n\t\t\t\t\t\tconst boldBit = (tokenStyle.bold ? FontStyle.Bold : 0) << MetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |= boldBit | MetadataConsts.SEMANTIC_USE_BOLD;\n\t\t\t\t\t}\n\t\t\t\t\tif (typeof tokenStyle.underline !== 'undefined') {\n\t\t\t\t\t\tconst underlineBit = (tokenStyle.underline ? FontStyle.Underline : 0) << MetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |= underlineBit | MetadataConsts.SEMANTIC_USE_UNDERLINE;\n\t\t\t\t\t}\n\t\t\t\t\tif (typeof tokenStyle.strikethrough !== 'undefined') {\n\t\t\t\t\t\tconst strikethroughBit = (tokenStyle.strikethrough ? FontStyle.Strikethrough : 0) << MetadataConsts.FONT_STYLE_OFFSET;\n\t\t\t\t\t\tmetadata |= strikethroughBit | MetadataConsts.SEMANTIC_USE_STRIKETHROUGH;\n\t\t\t\t\t}\n\t\t\t\t\tif (tokenStyle.foreground) {\n\t\t\t\t\t\tconst foregroundBits = (tokenStyle.foreground) << MetadataConsts.FOREGROUND_OFFSET;\n\t\t\t\t\t\tmetadata |= foregroundBits | MetadataConsts.SEMANTIC_USE_FOREGROUND;\n\t\t\t\t\t}\n\t\t\t\t\tif (metadata === 0) {\n\t\t\t\t\t\t// Nothing!\n\t\t\t\t\t\tmetadata = SemanticTokensProviderStylingConstants.NO_STYLING;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (ENABLE_TRACE && this._logService.getLevel() === LogLevel.Trace) {\n\t\t\t\t\tthis._logService.trace(`SemanticTokensProviderStyling: unknown token type index: ${tokenTypeIndex} for legend: ${JSON.stringify(this._legend.tokenTypes)}`);\n\t\t\t\t}\n\t\t\t\tmetadata = SemanticTokensProviderStylingConstants.NO_STYLING;\n\t\t\t\ttokenType = 'not-in-legend';\n\t\t\t}\n\t\t\tthis._hashTable.add(tokenTypeIndex, tokenModifierSet, encodedLanguageId, metadata);\n\n\t\t\tif (ENABLE_TRACE && this._logService.getLevel() === LogLevel.Trace) {\n\t\t\t\tthis._logService.trace(`SemanticTokensProviderStyling ${tokenTypeIndex} (${tokenType}) / ${tokenModifierSet} (${tokenModifiers.join(' ')}): foreground ${TokenMetadata.getForeground(metadata)}, fontStyle ${TokenMetadata.getFontStyle(metadata).toString(2)}`);\n\t\t\t}\n\t\t}\n\n\t\treturn metadata;\n\t}\n\n\tpublic warnOverlappingSemanticTokens(lineNumber: number, startColumn: number): void {\n\t\tif (!this._hasWarnedOverlappingTokens) {\n\t\t\tthis._hasWarnedOverlappingTokens = true;\n\t\t\tthis._logService.warn(`Overlapping semantic tokens detected at lineNumber ${lineNumber}, column ${startColumn}`);\n\t\t}\n\t}\n\n\tpublic warnInvalidLengthSemanticTokens(lineNumber: number, startColumn: number): void {\n\t\tif (!this._hasWarnedInvalidLengthTokens) {\n\t\t\tthis._hasWarnedInvalidLengthTokens = true;\n\t\t\tthis._logService.warn(`Semantic token with invalid length detected at lineNumber ${lineNumber}, column ${startColumn}`);\n\t\t}\n\t}\n\n\tpublic warnInvalidEditStart(previousResultId: string | undefined, resultId: string | undefined, editIndex: number, editStart: number, maxExpectedStart: number): void {\n\t\tif (!this._hasWarnedInvalidEditStart) {\n\t\t\tthis._hasWarnedInvalidEditStart = true;\n\t\t\tthis._logService.warn(`Invalid semantic tokens edit detected (previousResultId: ${previousResultId}, resultId: ${resultId}) at edit #${editIndex}: The provided start offset ${editStart} is outside the previous data (length ${maxExpectedStart}).`);\n\t\t}\n\t}\n\n}\n\nconst enum SemanticColoringConstants {\n\t/**\n\t * Let's aim at having 8KB buffers if possible...\n\t * So that would be 8192 / (5 * 4) = 409.6 tokens per area\n\t */\n\tDesiredTokensPerArea = 400,\n\n\t/**\n\t * Try to keep the total number of areas under 1024 if possible,\n\t * simply compensate by having more tokens per area...\n\t */\n\tDesiredMaxAreas = 1024,\n}\n\nexport function toMultilineTokens2(tokens: SemanticTokens, styling: SemanticTokensProviderStyling, languageId: string): SparseMultilineTokens[] {\n\tconst srcData = tokens.data;\n\tconst tokenCount = (tokens.data.length / 5) | 0;\n\tconst tokensPerArea = Math.max(Math.ceil(tokenCount / SemanticColoringConstants.DesiredMaxAreas), SemanticColoringConstants.DesiredTokensPerArea);\n\tconst result: SparseMultilineTokens[] = [];\n\n\tlet tokenIndex = 0;\n\tlet lastLineNumber = 1;\n\tlet lastStartCharacter = 0;\n\twhile (tokenIndex < tokenCount) {\n\t\tconst tokenStartIndex = tokenIndex;\n\t\tlet tokenEndIndex = Math.min(tokenStartIndex + tokensPerArea, tokenCount);\n\n\t\t// Keep tokens on the same line in the same area...\n\t\tif (tokenEndIndex < tokenCount) {\n\n\t\t\tlet smallTokenEndIndex = tokenEndIndex;\n\t\t\twhile (smallTokenEndIndex - 1 > tokenStartIndex && srcData[5 * smallTokenEndIndex] === 0) {\n\t\t\t\tsmallTokenEndIndex--;\n\t\t\t}\n\n\t\t\tif (smallTokenEndIndex - 1 === tokenStartIndex) {\n\t\t\t\t// there are so many tokens on this line that our area would be empty, we must now go right\n\t\t\t\tlet bigTokenEndIndex = tokenEndIndex;\n\t\t\t\twhile (bigTokenEndIndex + 1 < tokenCount && srcData[5 * bigTokenEndIndex] === 0) {\n\t\t\t\t\tbigTokenEndIndex++;\n\t\t\t\t}\n\t\t\t\ttokenEndIndex = bigTokenEndIndex;\n\t\t\t} else {\n\t\t\t\ttokenEndIndex = smallTokenEndIndex;\n\t\t\t}\n\t\t}\n\n\t\tlet destData = new Uint32Array((tokenEndIndex - tokenStartIndex) * 4);\n\t\tlet destOffset = 0;\n\t\tlet areaLine = 0;\n\t\tlet prevLineNumber = 0;\n\t\tlet prevEndCharacter = 0;\n\t\twhile (tokenIndex < tokenEndIndex) {\n\t\t\tconst srcOffset = 5 * tokenIndex;\n\t\t\tconst deltaLine = srcData[srcOffset];\n\t\t\tconst deltaCharacter = srcData[srcOffset + 1];\n\t\t\t// Casting both `lineNumber`, `startCharacter` and `endCharacter` here to uint32 using `|0`\n\t\t\t// to validate below with the actual values that will be inserted in the Uint32Array result\n\t\t\tconst lineNumber = (lastLineNumber + deltaLine) | 0;\n\t\t\tconst startCharacter = (deltaLine === 0 ? (lastStartCharacter + deltaCharacter) | 0 : deltaCharacter);\n\t\t\tconst length = srcData[srcOffset + 2];\n\t\t\tconst endCharacter = (startCharacter + length) | 0;\n\t\t\tconst tokenTypeIndex = srcData[srcOffset + 3];\n\t\t\tconst tokenModifierSet = srcData[srcOffset + 4];\n\n\t\t\tif (endCharacter <= startCharacter) {\n\t\t\t\t// this token is invalid (most likely a negative length casted to uint32)\n\t\t\t\tstyling.warnInvalidLengthSemanticTokens(lineNumber, startCharacter + 1);\n\t\t\t} else if (prevLineNumber === lineNumber && prevEndCharacter > startCharacter) {\n\t\t\t\t// this token overlaps with the previous token\n\t\t\t\tstyling.warnOverlappingSemanticTokens(lineNumber, startCharacter + 1);\n\t\t\t} else {\n\t\t\t\tconst metadata = styling.getMetadata(tokenTypeIndex, tokenModifierSet, languageId);\n\n\t\t\t\tif (metadata !== SemanticTokensProviderStylingConstants.NO_STYLING) {\n\t\t\t\t\tif (areaLine === 0) {\n\t\t\t\t\t\tareaLine = lineNumber;\n\t\t\t\t\t}\n\t\t\t\t\tdestData[destOffset] = lineNumber - areaLine;\n\t\t\t\t\tdestData[destOffset + 1] = startCharacter;\n\t\t\t\t\tdestData[destOffset + 2] = endCharacter;\n\t\t\t\t\tdestData[destOffset + 3] = metadata;\n\t\t\t\t\tdestOffset += 4;\n\n\t\t\t\t\tprevLineNumber = lineNumber;\n\t\t\t\t\tprevEndCharacter = endCharacter;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tlastLineNumber = lineNumber;\n\t\t\tlastStartCharacter = startCharacter;\n\t\t\ttokenIndex++;\n\t\t}\n\n\t\tif (destOffset !== destData.length) {\n\t\t\tdestData = destData.subarray(0, destOffset);\n\t\t}\n\n\t\tconst tokens = SparseMultilineTokens.create(areaLine, destData);\n\t\tresult.push(tokens);\n\t}\n\n\treturn result;\n}\n\nclass HashTableEntry {\n\tpublic readonly tokenTypeIndex: number;\n\tpublic readonly tokenModifierSet: number;\n\tpublic readonly languageId: number;\n\tpublic readonly metadata: number;\n\tpublic next: HashTableEntry | null;\n\n\tconstructor(tokenTypeIndex: number, tokenModifierSet: number, languageId: number, metadata: number) {\n\t\tthis.tokenTypeIndex = tokenTypeIndex;\n\t\tthis.tokenModifierSet = tokenModifierSet;\n\t\tthis.languageId = languageId;\n\t\tthis.metadata = metadata;\n\t\tthis.next = null;\n\t}\n}\n\nclass HashTable {\n\n\tprivate static _SIZES = [3, 7, 13, 31, 61, 127, 251, 509, 1021, 2039, 4093, 8191, 16381, 32749, 65521, 131071, 262139, 524287, 1048573, 2097143];\n\n\tprivate _elementsCount: number;\n\tprivate _currentLengthIndex: number;\n\tprivate _currentLength: number;\n\tprivate _growCount: number;\n\tprivate _elements: (HashTableEntry | null)[];\n\n\tconstructor() {\n\t\tthis._elementsCount = 0;\n\t\tthis._currentLengthIndex = 0;\n\t\tthis._currentLength = HashTable._SIZES[this._currentLengthIndex];\n\t\tthis._growCount = Math.round(this._currentLengthIndex + 1 < HashTable._SIZES.length ? 2 / 3 * this._currentLength : 0);\n\t\tthis._elements = [];\n\t\tHashTable._nullOutEntries(this._elements, this._currentLength);\n\t}\n\n\tprivate static _nullOutEntries(entries: (HashTableEntry | null)[], length: number): void {\n\t\tfor (let i = 0; i < length; i++) {\n\t\t\tentries[i] = null;\n\t\t}\n\t}\n\n\tprivate _hash2(n1: number, n2: number): number {\n\t\treturn (((n1 << 5) - n1) + n2) | 0;  // n1 * 31 + n2, keep as int32\n\t}\n\n\tprivate _hashFunc(tokenTypeIndex: number, tokenModifierSet: number, languageId: number): number {\n\t\treturn this._hash2(this._hash2(tokenTypeIndex, tokenModifierSet), languageId) % this._currentLength;\n\t}\n\n\tpublic get(tokenTypeIndex: number, tokenModifierSet: number, languageId: number): HashTableEntry | null {\n\t\tconst hash = this._hashFunc(tokenTypeIndex, tokenModifierSet, languageId);\n\n\t\tlet p = this._elements[hash];\n\t\twhile (p) {\n\t\t\tif (p.tokenTypeIndex === tokenTypeIndex && p.tokenModifierSet === tokenModifierSet && p.languageId === languageId) {\n\t\t\t\treturn p;\n\t\t\t}\n\t\t\tp = p.next;\n\t\t}\n\n\t\treturn null;\n\t}\n\n\tpublic add(tokenTypeIndex: number, tokenModifierSet: number, languageId: number, metadata: number): void {\n\t\tthis._elementsCount++;\n\t\tif (this._growCount !== 0 && this._elementsCount >= this._growCount) {\n\t\t\t// expand!\n\t\t\tconst oldElements = this._elements;\n\n\t\t\tthis._currentLengthIndex++;\n\t\t\tthis._currentLength = HashTable._SIZES[this._currentLengthIndex];\n\t\t\tthis._growCount = Math.round(this._currentLengthIndex + 1 < HashTable._SIZES.length ? 2 / 3 * this._currentLength : 0);\n\t\t\tthis._elements = [];\n\t\t\tHashTable._nullOutEntries(this._elements, this._currentLength);\n\n\t\t\tfor (const first of oldElements) {\n\t\t\t\tlet p = first;\n\t\t\t\twhile (p) {\n\t\t\t\t\tconst oldNext = p.next;\n\t\t\t\t\tp.next = null;\n\t\t\t\t\tthis._add(p);\n\t\t\t\t\tp = oldNext;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tthis._add(new HashTableEntry(tokenTypeIndex, tokenModifierSet, languageId, metadata));\n\t}\n\n\tprivate _add(element: HashTableEntry): void {\n\t\tconst hash = this._hashFunc(element.tokenTypeIndex, element.tokenModifierSet, element.languageId);\n\t\telement.next = this._elements[hash];\n\t\tthis._elements[hash] = element;\n\t}\n}\n"],
  "mappings": ";;;;;;;;;;;;AAKA,SAAS,sBAAsB,sBAAsB;AACrD,SAAS,WAAW,gBAAgB,qBAAqB;AACzD,SAAS,qBAAqB;AAC9B,SAAS,aAAa,gBAAgB;AACtC,SAAS,6BAA6B;AACtC,SAAS,wBAAwB;AAEjC,IAAW,yCAAX,kBAAWA,4CAAX;AACC,EAAAA,gFAAA,gBAAa,cAAb;AADU,SAAAA;AAAA,GAAA;AAIX,MAAM,eAAe;AAEd,IAAM,gCAAN,MAAoC;AAAA,EAO1C,YACkB,SACe,eACG,kBACL,aAC7B;AAJgB;AACe;AACG;AACL;AAE9B,SAAK,aAAa,IAAI,UAAU;AAAA,EACjC;AAAA,EAhCD,OAkB2C;AAAA;AAAA;AAAA,EAEzB;AAAA,EACT,8BAA8B;AAAA,EAC9B,gCAAgC;AAAA,EAChC,6BAA6B;AAAA,EAW9B,YAAY,gBAAwB,kBAA0B,YAA4B;AAChG,UAAM,oBAAoB,KAAK,iBAAiB,gBAAgB,iBAAiB,UAAU;AAC3F,UAAM,QAAQ,KAAK,WAAW,IAAI,gBAAgB,kBAAkB,iBAAiB;AACrF,QAAI;AACJ,QAAI,OAAO;AACV,iBAAW,MAAM;AACjB,UAAI,gBAAgB,KAAK,YAAY,SAAS,MAAM,SAAS,OAAO;AACnE,aAAK,YAAY,MAAM,0CAA0C,cAAc,MAAM,gBAAgB,gBAAgB,cAAc,cAAc,QAAQ,CAAC,eAAe,cAAc,aAAa,QAAQ,EAAE,SAAS,CAAC,CAAC,EAAE;AAAA,MAC5N;AAAA,IACD,OAAO;AACN,UAAI,YAAY,KAAK,QAAQ,WAAW,cAAc;AACtD,YAAM,iBAA2B,CAAC;AAClC,UAAI,WAAW;AACd,YAAI,cAAc;AAClB,iBAAS,gBAAgB,GAAG,cAAc,KAAK,gBAAgB,KAAK,QAAQ,eAAe,QAAQ,iBAAiB;AACnH,cAAI,cAAc,GAAG;AACpB,2BAAe,KAAK,KAAK,QAAQ,eAAe,aAAa,CAAC;AAAA,UAC/D;AACA,wBAAc,eAAe;AAAA,QAC9B;AACA,YAAI,gBAAgB,cAAc,KAAK,KAAK,YAAY,SAAS,MAAM,SAAS,OAAO;AACtF,eAAK,YAAY,MAAM,gEAAgE,iBAAiB,SAAS,CAAC,CAAC,gBAAgB,KAAK,UAAU,KAAK,QAAQ,cAAc,CAAC,EAAE;AAChL,yBAAe,KAAK,eAAe;AAAA,QACpC;AAEA,cAAM,aAAa,KAAK,cAAc,cAAc,EAAE,sBAAsB,WAAW,gBAAgB,UAAU;AACjH,YAAI,OAAO,eAAe,aAAa;AACtC,qBAAW;AAAA,QACZ,OAAO;AACN,qBAAW;AACX,cAAI,OAAO,WAAW,WAAW,aAAa;AAC7C,kBAAM,aAAa,WAAW,SAAS,UAAU,SAAS,MAAM,eAAe;AAC/E,wBAAY,YAAY,eAAe;AAAA,UACxC;AACA,cAAI,OAAO,WAAW,SAAS,aAAa;AAC3C,kBAAM,WAAW,WAAW,OAAO,UAAU,OAAO,MAAM,eAAe;AACzE,wBAAY,UAAU,eAAe;AAAA,UACtC;AACA,cAAI,OAAO,WAAW,cAAc,aAAa;AAChD,kBAAM,gBAAgB,WAAW,YAAY,UAAU,YAAY,MAAM,eAAe;AACxF,wBAAY,eAAe,eAAe;AAAA,UAC3C;AACA,cAAI,OAAO,WAAW,kBAAkB,aAAa;AACpD,kBAAM,oBAAoB,WAAW,gBAAgB,UAAU,gBAAgB,MAAM,eAAe;AACpG,wBAAY,mBAAmB,eAAe;AAAA,UAC/C;AACA,cAAI,WAAW,YAAY;AAC1B,kBAAM,iBAAkB,WAAW,cAAe,eAAe;AACjE,wBAAY,iBAAiB,eAAe;AAAA,UAC7C;AACA,cAAI,aAAa,GAAG;AAEnB,uBAAW;AAAA,UACZ;AAAA,QACD;AAAA,MACD,OAAO;AACN,YAAI,gBAAgB,KAAK,YAAY,SAAS,MAAM,SAAS,OAAO;AACnE,eAAK,YAAY,MAAM,4DAA4D,cAAc,gBAAgB,KAAK,UAAU,KAAK,QAAQ,UAAU,CAAC,EAAE;AAAA,QAC3J;AACA,mBAAW;AACX,oBAAY;AAAA,MACb;AACA,WAAK,WAAW,IAAI,gBAAgB,kBAAkB,mBAAmB,QAAQ;AAEjF,UAAI,gBAAgB,KAAK,YAAY,SAAS,MAAM,SAAS,OAAO;AACnE,aAAK,YAAY,MAAM,iCAAiC,cAAc,KAAK,SAAS,OAAO,gBAAgB,KAAK,eAAe,KAAK,GAAG,CAAC,iBAAiB,cAAc,cAAc,QAAQ,CAAC,eAAe,cAAc,aAAa,QAAQ,EAAE,SAAS,CAAC,CAAC,EAAE;AAAA,MAChQ;AAAA,IACD;AAEA,WAAO;AAAA,EACR;AAAA,EAEO,8BAA8B,YAAoB,aAA2B;AACnF,QAAI,CAAC,KAAK,6BAA6B;AACtC,WAAK,8BAA8B;AACnC,WAAK,YAAY,KAAK,sDAAsD,UAAU,YAAY,WAAW,EAAE;AAAA,IAChH;AAAA,EACD;AAAA,EAEO,gCAAgC,YAAoB,aAA2B;AACrF,QAAI,CAAC,KAAK,+BAA+B;AACxC,WAAK,gCAAgC;AACrC,WAAK,YAAY,KAAK,6DAA6D,UAAU,YAAY,WAAW,EAAE;AAAA,IACvH;AAAA,EACD;AAAA,EAEO,qBAAqB,kBAAsC,UAA8B,WAAmB,WAAmB,kBAAgC;AACrK,QAAI,CAAC,KAAK,4BAA4B;AACrC,WAAK,6BAA6B;AAClC,WAAK,YAAY,KAAK,4DAA4D,gBAAgB,eAAe,QAAQ,cAAc,SAAS,+BAA+B,SAAS,yCAAyC,gBAAgB,IAAI;AAAA,IACtP;AAAA,EACD;AAED;AA7Ga,gCAAN;AAAA,EASJ;AAAA,EACA;AAAA,EACA;AAAA,GAXU;AA+Gb,IAAW,4BAAX,kBAAWC,+BAAX;AAKC,EAAAA,sDAAA,0BAAuB,OAAvB;AAMA,EAAAA,sDAAA,qBAAkB,QAAlB;AAXU,SAAAA;AAAA,GAAA;AAcJ,SAAS,mBAAmB,QAAwB,SAAwC,YAA6C;AAC/I,QAAM,UAAU,OAAO;AACvB,QAAM,aAAc,OAAO,KAAK,SAAS,IAAK;AAC9C,QAAM,gBAAgB,KAAK,IAAI,KAAK,KAAK,aAAa,0BAAyC,GAAG,8BAA8C;AAChJ,QAAM,SAAkC,CAAC;AAEzC,MAAI,aAAa;AACjB,MAAI,iBAAiB;AACrB,MAAI,qBAAqB;AACzB,SAAO,aAAa,YAAY;AAC/B,UAAM,kBAAkB;AACxB,QAAI,gBAAgB,KAAK,IAAI,kBAAkB,eAAe,UAAU;AAGxE,QAAI,gBAAgB,YAAY;AAE/B,UAAI,qBAAqB;AACzB,aAAO,qBAAqB,IAAI,mBAAmB,QAAQ,IAAI,kBAAkB,MAAM,GAAG;AACzF;AAAA,MACD;AAEA,UAAI,qBAAqB,MAAM,iBAAiB;AAE/C,YAAI,mBAAmB;AACvB,eAAO,mBAAmB,IAAI,cAAc,QAAQ,IAAI,gBAAgB,MAAM,GAAG;AAChF;AAAA,QACD;AACA,wBAAgB;AAAA,MACjB,OAAO;AACN,wBAAgB;AAAA,MACjB;AAAA,IACD;AAEA,QAAI,WAAW,IAAI,aAAa,gBAAgB,mBAAmB,CAAC;AACpE,QAAI,aAAa;AACjB,QAAI,WAAW;AACf,QAAI,iBAAiB;AACrB,QAAI,mBAAmB;AACvB,WAAO,aAAa,eAAe;AAClC,YAAM,YAAY,IAAI;AACtB,YAAM,YAAY,QAAQ,SAAS;AACnC,YAAM,iBAAiB,QAAQ,YAAY,CAAC;AAG5C,YAAM,aAAc,iBAAiB,YAAa;AAClD,YAAM,iBAAkB,cAAc,IAAK,qBAAqB,iBAAkB,IAAI;AACtF,YAAM,SAAS,QAAQ,YAAY,CAAC;AACpC,YAAM,eAAgB,iBAAiB,SAAU;AACjD,YAAM,iBAAiB,QAAQ,YAAY,CAAC;AAC5C,YAAM,mBAAmB,QAAQ,YAAY,CAAC;AAE9C,UAAI,gBAAgB,gBAAgB;AAEnC,gBAAQ,gCAAgC,YAAY,iBAAiB,CAAC;AAAA,MACvE,WAAW,mBAAmB,cAAc,mBAAmB,gBAAgB;AAE9E,gBAAQ,8BAA8B,YAAY,iBAAiB,CAAC;AAAA,MACrE,OAAO;AACN,cAAM,WAAW,QAAQ,YAAY,gBAAgB,kBAAkB,UAAU;AAEjF,YAAI,aAAa,6BAAmD;AACnE,cAAI,aAAa,GAAG;AACnB,uBAAW;AAAA,UACZ;AACA,mBAAS,UAAU,IAAI,aAAa;AACpC,mBAAS,aAAa,CAAC,IAAI;AAC3B,mBAAS,aAAa,CAAC,IAAI;AAC3B,mBAAS,aAAa,CAAC,IAAI;AAC3B,wBAAc;AAEd,2BAAiB;AACjB,6BAAmB;AAAA,QACpB;AAAA,MACD;AAEA,uBAAiB;AACjB,2BAAqB;AACrB;AAAA,IACD;AAEA,QAAI,eAAe,SAAS,QAAQ;AACnC,iBAAW,SAAS,SAAS,GAAG,UAAU;AAAA,IAC3C;AAEA,UAAMC,UAAS,sBAAsB,OAAO,UAAU,QAAQ;AAC9D,WAAO,KAAKA,OAAM;AAAA,EACnB;AAEA,SAAO;AACR;AAzFgB;AA2FhB,MAAM,eAAe;AAAA,EA1OrB,OA0OqB;AAAA;AAAA;AAAA,EACJ;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACT;AAAA,EAEP,YAAY,gBAAwB,kBAA0B,YAAoB,UAAkB;AACnG,SAAK,iBAAiB;AACtB,SAAK,mBAAmB;AACxB,SAAK,aAAa;AAClB,SAAK,WAAW;AAChB,SAAK,OAAO;AAAA,EACb;AACD;AAEA,MAAM,UAAU;AAAA,EA1PhB,OA0PgB;AAAA;AAAA;AAAA,EAEf,OAAe,SAAS,CAAC,GAAG,GAAG,IAAI,IAAI,IAAI,KAAK,KAAK,KAAK,MAAM,MAAM,MAAM,MAAM,OAAO,OAAO,OAAO,QAAQ,QAAQ,QAAQ,SAAS,OAAO;AAAA,EAEvI;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EAER,cAAc;AACb,SAAK,iBAAiB;AACtB,SAAK,sBAAsB;AAC3B,SAAK,iBAAiB,UAAU,OAAO,KAAK,mBAAmB;AAC/D,SAAK,aAAa,KAAK,MAAM,KAAK,sBAAsB,IAAI,UAAU,OAAO,SAAS,IAAI,IAAI,KAAK,iBAAiB,CAAC;AACrH,SAAK,YAAY,CAAC;AAClB,cAAU,gBAAgB,KAAK,WAAW,KAAK,cAAc;AAAA,EAC9D;AAAA,EAEA,OAAe,gBAAgB,SAAoC,QAAsB;AACxF,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAChC,cAAQ,CAAC,IAAI;AAAA,IACd;AAAA,EACD;AAAA,EAEQ,OAAO,IAAY,IAAoB;AAC9C,YAAU,MAAM,KAAK,KAAM,KAAM;AAAA,EAClC;AAAA,EAEQ,UAAU,gBAAwB,kBAA0B,YAA4B;AAC/F,WAAO,KAAK,OAAO,KAAK,OAAO,gBAAgB,gBAAgB,GAAG,UAAU,IAAI,KAAK;AAAA,EACtF;AAAA,EAEO,IAAI,gBAAwB,kBAA0B,YAA2C;AACvG,UAAM,OAAO,KAAK,UAAU,gBAAgB,kBAAkB,UAAU;AAExE,QAAI,IAAI,KAAK,UAAU,IAAI;AAC3B,WAAO,GAAG;AACT,UAAI,EAAE,mBAAmB,kBAAkB,EAAE,qBAAqB,oBAAoB,EAAE,eAAe,YAAY;AAClH,eAAO;AAAA,MACR;AACA,UAAI,EAAE;AAAA,IACP;AAEA,WAAO;AAAA,EACR;AAAA,EAEO,IAAI,gBAAwB,kBAA0B,YAAoB,UAAwB;AACxG,SAAK;AACL,QAAI,KAAK,eAAe,KAAK,KAAK,kBAAkB,KAAK,YAAY;AAEpE,YAAM,cAAc,KAAK;AAEzB,WAAK;AACL,WAAK,iBAAiB,UAAU,OAAO,KAAK,mBAAmB;AAC/D,WAAK,aAAa,KAAK,MAAM,KAAK,sBAAsB,IAAI,UAAU,OAAO,SAAS,IAAI,IAAI,KAAK,iBAAiB,CAAC;AACrH,WAAK,YAAY,CAAC;AAClB,gBAAU,gBAAgB,KAAK,WAAW,KAAK,cAAc;AAE7D,iBAAW,SAAS,aAAa;AAChC,YAAI,IAAI;AACR,eAAO,GAAG;AACT,gBAAM,UAAU,EAAE;AAClB,YAAE,OAAO;AACT,eAAK,KAAK,CAAC;AACX,cAAI;AAAA,QACL;AAAA,MACD;AAAA,IACD;AACA,SAAK,KAAK,IAAI,eAAe,gBAAgB,kBAAkB,YAAY,QAAQ,CAAC;AAAA,EACrF;AAAA,EAEQ,KAAK,SAA+B;AAC3C,UAAM,OAAO,KAAK,UAAU,QAAQ,gBAAgB,QAAQ,kBAAkB,QAAQ,UAAU;AAChG,YAAQ,OAAO,KAAK,UAAU,IAAI;AAClC,SAAK,UAAU,IAAI,IAAI;AAAA,EACxB;AACD;",
  "names": ["SemanticTokensProviderStylingConstants", "SemanticColoringConstants", "tokens"]
}
